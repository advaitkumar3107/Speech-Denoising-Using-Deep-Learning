{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tpu_rnn",
      "provenance": [],
      "authorship_tag": "ABX9TyPAkvLN2nlw9k6zSL88YKjT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advaitkumar3107/Speech-Denoising-Using-Deep-Learning/blob/master/RCNN_speech_denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUNs5N2rbOX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "931812a9-c441-4e23-fb6a-7fc7a7590c51"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "import math\n",
        "import glob\n",
        "import sys\n",
        "import scipy\n",
        "import random\n",
        "import pywt\n",
        "import time\n",
        "from PIL import Image\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import librosa\n",
        "import librosa.display\n",
        "from tqdm import tqdm_notebook\n",
        "from scipy import signal\n",
        "from scipy.io.wavfile import read, write\n",
        "from numpy.fft import fft, ifft\n",
        "from google.colab import drive\n",
        "from torch.autograd import Variable\n",
        "from IPython.display import Audio\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive/sample_audio_dataset\n",
        "\n",
        "torch.cuda.manual_seed(7)\n",
        "torch.manual_seed(7)\n",
        "np.random.seed(7)\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/sample_audio_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ7cMEJbprCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,ids):\n",
        "    self.ids = ids\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "    self.length = len(self.ids) // 16\n",
        "\n",
        "    self.random_ids = random.sample(self.ids, self.length)\n",
        "\n",
        " #   self.mean = mean\n",
        " #   self.std = std\n",
        " #   self.mean_target = mean_target\n",
        " #   self.std_target = std_target\n",
        "    \n",
        "    for id_ in self.random_ids:\n",
        "      input_location = 'noisy_dataset/noisy_trainset_56spk_wav/' + id_\n",
        "      target_location = 'clean_dataset/' + id_\n",
        "      \n",
        "#      y, sr = librosa.load(input_location)\n",
        "#      D = y\n",
        "#      D = torch.from_numpy(D)\n",
        "#      input_ = D.unsqueeze_(0)\n",
        "#      self.inputs.append(input_)\n",
        "      y, _ = librosa.load(input_location)\n",
        "      ca, cd = pywt.dwt(y, 'db1')\n",
        "      ca, cd = torch.from_numpy(ca), torch.from_numpy(cd)\n",
        "      input_ = torch.cat((ca.unsqueeze_(1), cd.unsqueeze_(1)), axis = 1)\n",
        "      self.inputs.append(input_)\n",
        "\n",
        "#      y, sr = librosa.load(target_location)\n",
        "#      D = torch.from_numpy(y)\n",
        "#      target = D.unsqueeze_(0)\n",
        "#      target = input_ - target\n",
        "#      self.targets.append(target)\n",
        "      y, _ = librosa.load(target_location)\n",
        "      ca, cd = pywt.dwt(y, 'db1')\n",
        "      ca, cd = torch.from_numpy(ca), torch.from_numpy(cd)\n",
        "      target = torch.cat((ca.unsqueeze_(1), cd.unsqueeze_(1)), axis = 1)\n",
        "      self.targets.append(target)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    input_ = self.inputs[index]\n",
        "    target = self.targets[index]\n",
        "\n",
        "    return input_, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX_MFqt7BflI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_loader(dataset, train_percent, batch_size):\n",
        "  length = len(dataset)\n",
        "  train_length = int(train_percent*length/100)\n",
        "  val_length = length - train_length\n",
        "  train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_length, val_length])\n",
        "\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, True)\n",
        "  val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, False)\n",
        "\n",
        "  return train_dataloader, val_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7U0JmFYb8U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class rnn_model(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, batch_size, batch_first = True, dropout = 0.5):\n",
        "    super(rnn_model, self).__init__()\n",
        "    self.lstm1 = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim[0], num_layers = 1, bias = True, batch_first = batch_first, dropout = dropout, bidirectional = True)\n",
        "    self.linear1 = nn.Linear(2*hidden_dim[0], hidden_dim[0])\n",
        "\n",
        "    self.lstm2 = nn.LSTM(input_size = hidden_dim[0], hidden_size = hidden_dim[1], num_layers = 1, bias = True, batch_first = batch_first, dropout = dropout, bidirectional = True)\n",
        "    self.linear2 = nn.Linear(2*hidden_dim[1], hidden_dim[1])\n",
        "\n",
        "    self.lstm3 = nn.LSTM(input_size = hidden_dim[1], hidden_size = hidden_dim[2], num_layers = 1, bias = True, batch_first = batch_first, dropout = dropout, bidirectional = True)\n",
        "    self.linear3 = nn.Linear(2*hidden_dim[2], hidden_dim[2])\n",
        "\n",
        "    self.forward_hidden_state0 = nn.Parameter(torch.randn(2,batch_size,hidden_dim[0]).type(torch.FloatTensor), requires_grad = True)\n",
        "    self.forward_cell_state0 = nn.Parameter(torch.randn(2,batch_size,hidden_dim[0]).type(torch.FloatTensor), requires_grad = True)\n",
        "\n",
        "    self.forward_hidden_state1 = nn.Parameter(torch.randn(2,batch_size,hidden_dim[1]).type(torch.FloatTensor), requires_grad = True)\n",
        "    self.forward_cell_state1 = nn.Parameter(torch.randn(2,batch_size,hidden_dim[1]).type(torch.FloatTensor), requires_grad = True)\n",
        "\n",
        "    self.forward_hidden_state2 = nn.Parameter(torch.randn(2,batch_size,hidden_dim[2]).type(torch.FloatTensor), requires_grad = True)\n",
        "    self.forward_cell_state2 = nn.Parameter(torch.randn(2,batch_size,hidden_dim[2]).type(torch.FloatTensor), requires_grad = True)\n",
        "\n",
        "\n",
        "  def forward(self, input_):\n",
        "#    print(input_.size())\n",
        "    forward_hidden_states = (self.forward_hidden_state0, self.forward_cell_state0)\n",
        "    output,_ = self.lstm1(input_, forward_hidden_states)\n",
        "#    print(output.size())\n",
        "    output = self.linear1(output)\n",
        "    forward_hidden_states = (self.forward_hidden_state1, self.forward_cell_state1)\n",
        "    output,_ = self.lstm2(output, forward_hidden_states)\n",
        "    output = self.linear2(output)\n",
        "\n",
        "    forward_hidden_states = (self.forward_hidden_state2, self.forward_cell_state2)\n",
        "    output,_ = self.lstm3(output, forward_hidden_states)\n",
        "    output = self.linear3(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3udTzpVMfLyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, dataloader, optimizer, loss):\n",
        "  model.train()\n",
        "  train_losses.append(0)\n",
        "  progbar = tqdm_notebook(total = len(dataloader), desc = 'Train')\n",
        "\n",
        "  for i, (inputs, targets) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    inputs, targets = inputs.cuda(), targets.cuda()\n",
        "    outputs = model(inputs)\n",
        "#    outputs = unpack_outputs(outputs)\n",
        "    error = loss(outputs, targets)\n",
        "    error.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses[-1] = train_losses[-1] + error.data\n",
        "    progbar.set_description('Train (loss=%.4f)' % (train_losses[-1]/(i+1)))\n",
        "    progbar.update(1)\n",
        "\n",
        "  train_losses[-1] = train_losses[-1]/len(dataloader)\n",
        "\n",
        "    \n",
        "def val(model, dataloader, loss):\n",
        "  global best_loss\n",
        "  model.eval()\n",
        "  val_losses.append(0)\n",
        "  progbar = tqdm_notebook(total = len(dataloader), desc = 'Val')\n",
        "\n",
        "  for i, (inputs, targets) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    inputs, targets = inputs.cuda(), targets.cuda()\n",
        "    outputs = model(inputs)\n",
        "#    outputs = unpack_outputs(outputs)\n",
        "    error = loss(outputs, targets)\n",
        "\n",
        "    val_losses[-1] = val_losses[-1] + error.data\n",
        "    progbar.set_description('Val (loss=%.4f)' % (val_losses[-1]/(i+1)))\n",
        "    progbar.update(1)\n",
        "\n",
        "  val_losses[-1] = val_losses[-1]/len(dataloader)\n",
        "\n",
        "  if val_losses[-1] < best_loss:\n",
        "    best_loss = error\n",
        "    checkpoints = {'model' : model}\n",
        "    print(\"SAVING.......................\")\n",
        "    torch.save(checkpoints, 'rnn_denoising_best.ckpt.t7')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKEneOL7vXqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1\n",
        "train_percent = 80\n",
        "input_dim = 2\n",
        "hidden_dim = [8,4,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4_rYEAT0Jog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "9e76479c-3894-4e5e-f539-e259b2596823"
      },
      "source": [
        "ids = os.listdir('clean_dataset')\n",
        "dataset = AudioDataset(ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-62c147f64fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-dfbe2cdc8e4c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ids)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#      input_ = D.unsqueeze_(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#      self.inputs.append(input_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'db1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/gdrive/My Drive/sample_audio_dataset/noisy_dataset/noisy_trainset_56spk_wav/p374_091.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GCoR09t-7WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, val_loader = dataset_loader(dataset, train_percent, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX4fkKjs2KaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoints = torch.load('rnn_denoising_load.ckpt.t7')\n",
        "model = checkpoints['model']\n",
        "epochs = 2000 - checkpoints['epoch']\n",
        "#model = rnn_model(input_dim, hidden_dim, batch_size).cuda()\n",
        "loss = nn.L1Loss(reduction = 'sum')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)\n",
        "#best_loss = 1e5\n",
        "best_loss = checkpoints['best_loss']\n",
        "train_losses = []\n",
        "val_losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX1QBctz3xGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  train(model, train_loader, optimizer, loss)\n",
        "\n",
        "  checkpoints = {'model' : model, 'best_loss' : best_loss, 'epoch' : epoch}\n",
        "  torch.save(checkpoints, 'rnn_denoising_load.ckpt.t7')\n",
        "\n",
        "  val(model, val_loader, loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Ur5mIi603L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear1 = nn.Linear(10,20)\n",
        "a = torch.ones((1,3,10))\n",
        "output = linear1(a)\n",
        "output.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mukjGK-79Q4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lengths = get_sizes(d)\n",
        "sorted_lengths = get_sizes(e)\n",
        "packed_inputs = nn.utils.rnn.pack_padded_sequence(padded_inputs_sorted, sorted_lengths, enforce_sorted = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMAUfBC-cHB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.randn((23433,2))\n",
        "b = torch.randn((52321,2))\n",
        "c = torch.randn((33232,2))\n",
        "\n",
        "d = [a,b,c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWJcov3P-lEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "packed_train_inputs.data.size()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}